{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECYAKBiM0zA_",
        "outputId": "08c475f1-6c23-41b2-cb9a-e148c3e56547",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CHEMENG177'...\n",
            "remote: Enumerating objects: 45, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 45 (delta 21), reused 9 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (45/45), 688.37 KiB | 6.68 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n",
            "/content/CHEMENG177\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!git clone  https://github.com/daniela-figueroa/CHEMENG177\n",
        "\n",
        "%cd CHEMENG177\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIB8gds_0c-s",
        "outputId": "333eb709-3493-4a6b-a735-77345480c921"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'CALiSol-23 Dataset.csv'         lasso_final.ipynb                 ridge.ipynb\n",
            " CALiSol-23.ipynb               'Pre-processed CALiSol Data.csv'\n",
            "'Data_Preprocessing (1).ipynb'   README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "_S0_tr-uJQOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "ZgdPeSeCIdfC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Neural Network Class Defined"
      ],
      "metadata": {
        "id": "NXg2MvZFJV1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConductivityNN:\n",
        "    def __init__(self, input_dim):\n",
        "        \"\"\"Initialize the Feedforward Neural Network\"\"\"\n",
        "        self.model = Sequential([\n",
        "            Input(shape=(input_dim,)),\n",
        "            Dense(64, activation='relu'),\n",
        "            Dense(128, activation='relu'),\n",
        "            Dropout(0.2),\n",
        "            Dense(64, activation='relu'),\n",
        "            Dense(1)  # Output layer for regression\n",
        "        ])\n",
        "        self.model.compile(optimizer='adam', loss='mse', metrics=['r2_score'])\n",
        "\n",
        "    def train(self, X_train, y_train, epochs=50, batch_size=32):\n",
        "        \"\"\"Train the model using a validation set\"\"\"\n",
        "        self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        \"\"\"Predict conductivity\"\"\"\n",
        "        return self.model.predict(X_test)\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        \"\"\"Evaluate model\"\"\"\n",
        "        return self.model.evaluate(X_test, y_test, verbose=0)\n"
      ],
      "metadata": {
        "id": "ro_NZ0CqJcNx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Wrangling"
      ],
      "metadata": {
        "id": "lXagCrD41Xgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"Pre-processed CALiSol Data.csv\")\n",
        "print(dataset.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x-3wIcg08vC",
        "outputId": "96dbb092-fa5a-4fbc-9f3b-6218ce3465db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13302, 46)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.drop(columns=['Unnamed: 0'])\n",
        "print(dataset.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6MpKxdg1Qda",
        "outputId": "218b489e-2529-46ac-d83d-4015a289e6d3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13302, 45)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dictionaries"
      ],
      "metadata": {
        "id": "f_xhBxZpyWTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "molar_weights = {'EC': 88.06,\n",
        "       'PC' : 102.08, 'DMC' : 90.08,'EMC' : 104.10, 'DEC' : 118.132,\n",
        "        'DME' : 90.12, 'DMSO' : 78.13, 'AN': 41.05, 'MOEMC': 134.13, 'TFP': 344.07, 'EA' : 88.10,\n",
        "       'MA': 74.08, 'FEC': 106.05, 'DOL': 74.08, '2-MeTHF' : 86.13, 'DMM': 162.2, 'Freon 11' : 137.36,\n",
        "       'Methylene chloride' : 84.93,\n",
        "       'THF' : 72.10, 'Toluene' : 92.14, 'Sulfolane' : 120.17, '2-Glyme' : 134.17, '3-Glyme' : 178.22,\n",
        "                 '4-Glyme' : 222.28,\n",
        "       '3-Me-2-Oxazolidinone' : 101.10, '3-MeSulfolane' : 134.20, 'Ethyldiglyme': 134.17, 'DMF' : 73.09,\n",
        "       'Ethylbenzene' : 106.17, 'Ethylmonoglyme' : 76.10, 'Benzene' : 78.11, 'g-Butyrolactone' : 86.09,\n",
        "       'Cumene' : 120.19, 'Propylsulfone' : 150.24, 'Pseudocumeme' : 120.19, 'TEOS' : 208.33, 'm-Xylene' : 106.17,\n",
        "       'o-Xylene' : 106.16} # Molar weights of different organic solvents  [g / mol]\n",
        "molar_weights_salts = {'LiPF6' : 151.91, 'LiBF4': 93.75,\n",
        "                      'LiFSI': 187.7, 'LiTDI' : 192.1, 'LiPDI' : 242.1, 'LiTFSI' : 287.07, 'LiClO4' : 160.44, 'LiAsF6' : 195.9,\n",
        " 'LiBOB' : 193.79, 'LiCF3SO3' : 156.01, 'LiBPFPB' : 193.8, 'LiBMB': 221.85, 'LiN(CF3SO2)2' : 287.07} # Molar weights of salts in [g / mol]. Note that LiClO4 exists in hydrous and anyhydrous form\n",
        "# Note that the weight of LiBMB was calculated theoretically\n",
        "names_salts = {'LiPF6' : \"Lithium hexafluorophosphate\", 'LiBF4': \"Lithium tetrafluoroborate\",\n",
        "                      'LiFSI': \"Lithium Bis(fluorosulfonyl)imide\", 'LiTDI' : \"lithium 2-trifluoromethyl-4,5-dicyanoimidazole\",\n",
        "               'LiPDI' : \"lithium 4,5-dicyano-2-(pentafluoroethyl)imidazolide\", 'LiTFSI': \"Lithium bis(trifluoromethanesulfonyl)imide\",\n",
        "               'LiClO4' : \"Lithium perchlorate\", 'LiAsF6' : \"Lithium hexafluoroarsenate(V)\",\n",
        " 'LiBOB' : \"Lithium bis(oxalato)borate\", 'LiCF3SO3' : \"Lithium triflate\", 'LiBPFPB' : \"Lithium bis(oxalate)borate\",\n",
        "               'LiBMB' : \"lithium bis(malonato)borate\", 'LiN(CF3SO2)2' : \"lithium bis(trifluoromethanesulfonimide)\"}\n",
        "\n",
        "names_solvents = {'EC' : \"Ethylene carbonate\",\n",
        "       'PC' : \"Propylene carbonate\", 'DMC' : \"Dimethyl carbonate\", 'EMC' : \"Ethyl Methyl Carbonate\",\n",
        "         'DEC' : \"​Diethyl carbonate\", 'DME' : \"Dimethoxyethane\", 'DMSO' : \"Dimethyl sulfoxide\", 'AN' : \"Acetonitrile\", 'MOEMC' : \"2-Methoxyethyl (methyl) carbonate\",\n",
        "         'TFP' : \"Tris(2,2,2-trifluoroethyl) phosphate\", 'EA' : \"Ethyl acetate\",\n",
        "       'MA' : \"Methyl acetate\", 'FEC' : \"Fluoroethylene carbonate\", 'DOL': \"Dioxolane\"\n",
        "         , '2-MeTHF': \"2-Methyltetrahydrofuran\", 'DMM' : \"Dipropylene glycol dimethyl ether\",\n",
        "         'Freon 11' : \"Trichlorofluoromethane\", 'Methylene chloride' : 'Methylene chloride',\n",
        "       'THF' : \"Tetrahydrofuran\", 'Toluene' : \"Toluene\", 'Sulfolane' : \"Sulfolane\",\n",
        "         '2-Glyme': \"Diglyme\", '3-Glyme': \"Triglyme\", '4-Glyme': \"tetraglyme\",\n",
        "       '3-Me-2-Oxazolidinone' : \"3-Me-2-Oxazolidinone\", '3-MeSulfolane' : \"3-Methylsulfolane\",\n",
        "         'Ethyldiglyme' : \"2-(2-Ethoxyethoxy)ethanol\", 'DMF' : \"Dimethylformamide\",\n",
        "       'Ethylbenzene': 'Ethylbenzene', 'Ethylmonoglyme': \"ethylene glycol monomethyl\", 'Benzene' : \"Benzene\", 'g-Butyrolactone' : \"gamma-Butyrolactone\",\n",
        "       'Cumene' : \"Cumene\", 'Propylsulfone' : 'Propylsulfone', 'Pseudocumeme' : \"1,2,4-Trimethylbenzene\", 'TEOS' : \"Tetraethyl orthosilicate\", 'm-Xylene' : 'm-Xylene',\n",
        "       'o-Xylene' : 'o-Xylene'\n",
        "}\n",
        "\n",
        "densities = {'EC': 1.3210,\n",
        "       'PC' : 1.205, 'DMC' : 1.07, 'EMC' : 0.902, 'DEC' : 0.975,\n",
        "        'DME' : 0.86, 'DMSO' : 1.1004, 'AN': 0.786, 'MOEMC': 1.5, 'TFP': 1.487, 'EA' : 0.902,\n",
        "       'MA': 0.932, 'FEC': 1.454, 'DOL': 1.06, '2-MeTHF' : 0.854, 'DMM': 0.902, 'Freon 11': 1.49, 'Methylene chloride': 1.33,\n",
        "       'THF': 0.888, 'Toluene' : 0.867, 'Sulfolane' : 1.26, '2-Glyme': 0.937, '3-Glyme': 0.986, '4-Glyme': 1.009,\n",
        "       '3-Me-2-Oxazolidinone': 1.17, '3-MeSulfolane': 1.20, 'Ethyldiglyme' : 0.937, 'DMF': 0.944,\n",
        "       'Ethylbenzene': 0.866, 'Ethylmonoglyme': 0.965, 'Benzene': 0.876, 'g-Butyrolactone' : 1.13,\n",
        "       'Cumene': 0.862, 'Propylsulfone' : 1.109, 'Pseudocumeme': 0.876, 'TEOS': 0.940, 'm-Xylene' : 0.860,\n",
        "       'o-Xylene': 0.87596} # g / cm3 = g / ml at 25 C\n",
        "\n",
        "#NOTE: The salt density values for LiPDI is approximated based off of LiTDI, and the salt desnity values for LiBPFPB and LiBMB are approximated off of LiBOB.\n",
        "densities_salts = {'LiPF6' : 2.84, 'LiBF4': 0.852,\n",
        "                      'LiFSI': 1.052, 'LiTDI' : 2.2, 'LiPDI' : 2.1, 'LiTFSI' : 1.33, 'LiClO4' : 2.42, 'LiAsF6' : 2.32,\n",
        " 'LiBOB' : 2.021, 'LiCF3SO3' : 1.9, 'LiBPFPB' : 2.10, 'LiBMB': 2.00, 'LiN(CF3SO2)2' : 1.33}\n"
      ],
      "metadata": {
        "id": "yFldorqqzbl4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the data of the 4 salts with the most data\n",
        "\n"
      ],
      "metadata": {
        "id": "IKVlZXoTyct4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#separating data by salt\n",
        "salt_datas = {}\n",
        "X = {}\n",
        "y = {}\n",
        "relevant_salts = np.array([])\n",
        "for salt in names_salts.keys():\n",
        "  salt_datas[salt] = dataset[dataset['salt'] == salt]\n",
        "  trials = len(salt_datas[salt])\n",
        "  if trials > 1000:\n",
        "    relevant_salts = np.append(relevant_salts, salt)\n",
        "    print(f\"{salt} data has shape {salt_datas[salt].shape}\")\n",
        "    X[salt] = salt_datas[salt].iloc[:, 2:]\n",
        "    X[salt] = X[salt].drop(['salt', 'c units', 'solvent ratio type'],axis=1)\n",
        "    y[salt] = salt_datas[salt]['k']\n",
        "print(X.keys())\n",
        "print(y.keys())\n",
        "print(relevant_salts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmF-tRUN27YW",
        "outputId": "a653a754-f553-4485-87ca-53ac4ae2d79b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LiPF6 data has shape (4706, 45)\n",
            "LiBF4 data has shape (2943, 45)\n",
            "LiAsF6 data has shape (1040, 45)\n",
            "LiBOB data has shape (3699, 45)\n",
            "dict_keys(['LiPF6', 'LiBF4', 'LiAsF6', 'LiBOB'])\n",
            "dict_keys(['LiPF6', 'LiBF4', 'LiAsF6', 'LiBOB'])\n",
            "['LiPF6' 'LiBF4' 'LiAsF6' 'LiBOB']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Train and Evaluate Models For Hyperparameter Optimization"
      ],
      "metadata": {
        "id": "qEEjfwxP4MHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross Validation Process to Select Hyperparameters"
      ],
      "metadata": {
        "id": "rxe-52ZxwlAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "\n",
        "k_folds = 5  # Number of splits\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Hyperparameter grid\n",
        "epochs_list = [50, 100]\n",
        "batch_sizes = [32, 64]\n",
        "\n",
        "best_models = {}\n",
        "best_hyperparams = {}\n",
        "best_model_mse = {}\n",
        "best_model_std = {}\n",
        "best_model_r2 = {}\n",
        "\n",
        "X_fulltrain = {}\n",
        "X_test = {}\n",
        "y_fulltrain = {}\n",
        "y_test = {}\n",
        "\n",
        "for salt in X.keys():\n",
        "    print(f\"\\nPerforming Grid Search with {k_folds}-Fold CV for {salt}...\\n\")\n",
        "\n",
        "    X_data = X[salt]\n",
        "    y_data = y[salt]\n",
        "\n",
        "    # 10% of data held out for testing\n",
        "    X_fulltrain[salt], X_test[salt], y_fulltrain[salt], y_test[salt] = train_test_split(X_data, y_data, test_size=0.1,train_size=0.9, random_state=42)\n",
        "    best_mse = float(\"inf\")\n",
        "    best_r2 = float(\"-inf\")\n",
        "    best_model = None\n",
        "    best_params = None\n",
        "\n",
        "\n",
        "    # Iterate over all hyperparameter combinations\n",
        "    for epochs, batch_size in product(epochs_list, batch_sizes):\n",
        "        print(f\"  \\nEvaluating: epochs={epochs}, batch_size={batch_size}\")\n",
        "\n",
        "        fold_mse_scores = []\n",
        "        fold_r2 = []\n",
        "\n",
        "        # Cross-validation\n",
        "        for fold, (train_idx, test_idx) in enumerate(kf.split(X_fulltrain[salt])):\n",
        "            print(f\"  Fold {fold + 1}/{k_folds}...\")\n",
        "            # Split data into train/test for this fold\n",
        "            X_tr, X_val = X_fulltrain[salt].iloc[train_idx], X_fulltrain[salt].iloc[test_idx]\n",
        "            y_tr, y_val = y_fulltrain[salt].iloc[train_idx], y_fulltrain[salt].iloc[test_idx]\n",
        "\n",
        "            # Scale the data\n",
        "            scaler = StandardScaler() # should scaler be per fold or when data is initialized\n",
        "            X_tr = scaler.fit_transform(X_tr)\n",
        "            X_val = scaler.transform(X_val)\n",
        "\n",
        "            # Train the model\n",
        "            model = ConductivityNN(input_dim=X_tr.shape[1])\n",
        "            model.train(X_tr, y_tr, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "            # Evaluate the model on this fold\n",
        "            mse, r2 = model.evaluate(X_val, y_val)\n",
        "            fold_mse_scores.append(mse)\n",
        "            fold_r2.append(r2)\n",
        "\n",
        "        std_mse = np.std(fold_mse_scores)\n",
        "        mean_mse = np.mean(fold_mse_scores)\n",
        "        mean_r2 = np.mean(fold_r2)\n",
        "        print(f\"\\nFinal results for {salt} with {epochs} epochs and {batch_size} batch size:\")\n",
        "        print(f\"  Mean MSE: {mean_mse:.4f} ± {std_mse:.4f}\")\n",
        "        print(f\"  Mean R2: {mean_r2:.4f}\")\n",
        "\n",
        "        # Update best model if this one is better\n",
        "        if (mean_mse < best_mse and mean_r2 == best_r2) or (mean_r2 > best_r2):\n",
        "            best_mse = mean_mse\n",
        "            best_model = model\n",
        "            best_params = (epochs, batch_size)\n",
        "            best_std = std_mse\n",
        "            best_r2 = mean_r2\n",
        "\n",
        "    # Store the best model, parameters, and scaler\n",
        "    best_models[salt] = best_model\n",
        "    best_hyperparams[salt] = best_params\n",
        "    best_model_mse[salt] = best_mse\n",
        "    best_model_std[salt] = best_std\n",
        "    best_model_r2[salt] = best_r2\n",
        "    print(f\"\\nBest Model for {salt}:\")\n",
        "    print(f\"  Epochs: {best_hyperparams[salt][0]}, Batch Size: {best_hyperparams[salt][1]}\")\n",
        "    print(f\"  Mean MSE: {best_model_mse[salt]:.4f} ± {best_model_std[salt]:.4f}\")\n",
        "    print(f\"  Mean R2: {best_model_r2[salt]:.4f}\")"
      ],
      "metadata": {
        "id": "Ve7mtWLMJwC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0894660-0d07-4a61-c5b1-2425507449a5",
        "collapsed": true
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performing Grid Search with 5-Fold CV for LiPF6...\n",
            "\n",
            "  \n",
            "Evaluating: epochs=50, batch_size=32\n",
            "  Fold 1/5...\n",
            "  Fold 2/5...\n",
            "  Fold 3/5...\n",
            "  Fold 4/5...\n",
            "  Fold 5/5...\n",
            "\n",
            "Final results for LiPF6 with 50 epochs and 32 batch size:\n",
            "  Mean MSE: 0.2173 ± 0.0714\n",
            "  Mean R2: 0.9873\n",
            "  \n",
            "Evaluating: epochs=50, batch_size=64\n",
            "  Fold 1/5...\n",
            "  Fold 2/5...\n",
            "  Fold 3/5...\n",
            "  Fold 4/5...\n",
            "  Fold 5/5...\n",
            "\n",
            "Final results for LiPF6 with 50 epochs and 64 batch size:\n",
            "  Mean MSE: 0.2522 ± 0.0740\n",
            "  Mean R2: 0.9853\n",
            "  \n",
            "Evaluating: epochs=100, batch_size=32\n",
            "  Fold 1/5...\n",
            "  Fold 2/5...\n",
            "  Fold 3/5...\n",
            "  Fold 4/5...\n",
            "  Fold 5/5...\n",
            "\n",
            "Final results for LiPF6 with 100 epochs and 32 batch size:\n",
            "  Mean MSE: 0.2130 ± 0.0847\n",
            "  Mean R2: 0.9876\n",
            "  \n",
            "Evaluating: epochs=100, batch_size=64\n",
            "  Fold 1/5...\n",
            "  Fold 2/5...\n",
            "  Fold 3/5...\n",
            "  Fold 4/5...\n",
            "  Fold 5/5...\n",
            "\n",
            "Final results for LiPF6 with 100 epochs and 64 batch size:\n",
            "  Mean MSE: 0.2029 ± 0.0388\n",
            "  Mean R2: 0.9882\n",
            "\n",
            "Best Model for LiPF6:\n",
            "  Epochs: 100, Batch Size: 64\n",
            "  Mean MSE: 0.2029 ± 0.0388\n",
            "  Mean R2: 0.9882\n",
            "\n",
            "Performing Grid Search with 5-Fold CV for LiBF4...\n",
            "\n",
            "  \n",
            "Evaluating: epochs=50, batch_size=32\n",
            "  Fold 1/5...\n",
            "  Fold 2/5...\n",
            "  Fold 3/5...\n",
            "  Fold 4/5...\n",
            "  Fold 5/5...\n",
            "\n",
            "Final results for LiBF4 with 50 epochs and 32 batch size:\n",
            "  Mean MSE: 0.4321 ± 0.0338\n",
            "  Mean R2: 0.8484\n",
            "  \n",
            "Evaluating: epochs=50, batch_size=64\n",
            "  Fold 1/5...\n",
            "  Fold 2/5...\n",
            "  Fold 3/5...\n",
            "  Fold 4/5...\n",
            "  Fold 5/5...\n",
            "\n",
            "Final results for LiBF4 with 50 epochs and 64 batch size:\n",
            "  Mean MSE: 0.4295 ± 0.0419\n",
            "  Mean R2: 0.8495\n",
            "  \n",
            "Evaluating: epochs=100, batch_size=32\n",
            "  Fold 1/5...\n",
            "  Fold 2/5...\n",
            "  Fold 3/5...\n",
            "  Fold 4/5...\n",
            "  Fold 5/5...\n",
            "\n",
            "Final results for LiBF4 with 100 epochs and 32 batch size:\n",
            "  Mean MSE: 0.4140 ± 0.0348\n",
            "  Mean R2: 0.8547\n",
            "  \n",
            "Evaluating: epochs=100, batch_size=64\n",
            "  Fold 1/5...\n",
            "  Fold 2/5...\n",
            "  Fold 3/5...\n",
            "  Fold 4/5...\n",
            "  Fold 5/5...\n",
            "\n",
            "Final results for LiBF4 with 100 epochs and 64 batch size:\n",
            "  Mean MSE: 0.4154 ± 0.0348\n",
            "  Mean R2: 0.8542\n",
            "\n",
            "Best Model for LiBF4:\n",
            "  Epochs: 100, Batch Size: 32\n",
            "  Mean MSE: 0.4140 ± 0.0348\n",
            "  Mean R2: 0.8547\n",
            "\n",
            "Performing Grid Search with 5-Fold CV for LiAsF6...\n",
            "\n",
            "  \n",
            "Evaluating: epochs=50, batch_size=32\n",
            "  Fold 1/5...\n",
            "  Fold 2/5...\n",
            "  Fold 3/5...\n",
            "  Fold 4/5...\n",
            "  Fold 5/5...\n",
            "\n",
            "Final results for LiAsF6 with 50 epochs and 32 batch size:\n",
            "  Mean MSE: 1.2737 ± 0.3138\n",
            "  Mean R2: 0.9638\n",
            "  \n",
            "Evaluating: epochs=50, batch_size=64\n",
            "  Fold 1/5...\n",
            "  Fold 2/5...\n",
            "  Fold 3/5...\n",
            "  Fold 4/5...\n",
            "  Fold 5/5...\n",
            "\n",
            "Final results for LiAsF6 with 50 epochs and 64 batch size:\n",
            "  Mean MSE: 1.5193 ± 0.3532\n",
            "  Mean R2: 0.9572\n",
            "  \n",
            "Evaluating: epochs=100, batch_size=32\n",
            "  Fold 1/5...\n",
            "  Fold 2/5...\n",
            "  Fold 3/5...\n",
            "  Fold 4/5...\n",
            "  Fold 5/5...\n",
            "\n",
            "Final results for LiAsF6 with 100 epochs and 32 batch size:\n",
            "  Mean MSE: 0.8617 ± 0.3394\n",
            "  Mean R2: 0.9755\n",
            "  \n",
            "Evaluating: epochs=100, batch_size=64\n",
            "  Fold 1/5...\n",
            "  Fold 2/5...\n",
            "  Fold 3/5...\n",
            "  Fold 4/5...\n",
            "  Fold 5/5...\n",
            "\n",
            "Final results for LiAsF6 with 100 epochs and 64 batch size:\n",
            "  Mean MSE: 1.1496 ± 0.3145\n",
            "  Mean R2: 0.9673\n",
            "\n",
            "Best Model for LiAsF6:\n",
            "  Epochs: 100, Batch Size: 32\n",
            "  Mean MSE: 0.8617 ± 0.3394\n",
            "  Mean R2: 0.9755\n",
            "\n",
            "Performing Grid Search with 5-Fold CV for LiBOB...\n",
            "\n",
            "  \n",
            "Evaluating: epochs=50, batch_size=32\n",
            "  Fold 1/5...\n",
            "  Fold 2/5...\n",
            "  Fold 3/5...\n",
            "  Fold 4/5...\n",
            "  Fold 5/5...\n",
            "\n",
            "Final results for LiBOB with 50 epochs and 32 batch size:\n",
            "  Mean MSE: 0.6825 ± 0.2716\n",
            "  Mean R2: 0.9522\n",
            "  \n",
            "Evaluating: epochs=50, batch_size=64\n",
            "  Fold 1/5...\n",
            "  Fold 2/5...\n",
            "  Fold 3/5...\n",
            "  Fold 4/5...\n",
            "  Fold 5/5...\n",
            "\n",
            "Final results for LiBOB with 50 epochs and 64 batch size:\n",
            "  Mean MSE: 0.6174 ± 0.1479\n",
            "  Mean R2: 0.9561\n",
            "  \n",
            "Evaluating: epochs=100, batch_size=32\n",
            "  Fold 1/5...\n",
            "  Fold 2/5...\n",
            "  Fold 3/5...\n",
            "  Fold 4/5...\n",
            "  Fold 5/5...\n",
            "\n",
            "Final results for LiBOB with 100 epochs and 32 batch size:\n",
            "  Mean MSE: 0.5979 ± 0.2319\n",
            "  Mean R2: 0.9582\n",
            "  \n",
            "Evaluating: epochs=100, batch_size=64\n",
            "  Fold 1/5...\n",
            "  Fold 2/5...\n",
            "  Fold 3/5...\n",
            "  Fold 4/5...\n",
            "  Fold 5/5...\n",
            "\n",
            "Final results for LiBOB with 100 epochs and 64 batch size:\n",
            "  Mean MSE: 0.5552 ± 0.1388\n",
            "  Mean R2: 0.9606\n",
            "\n",
            "Best Model for LiBOB:\n",
            "  Epochs: 100, Batch Size: 64\n",
            "  Mean MSE: 0.5552 ± 0.1388\n",
            "  Mean R2: 0.9606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Final Training and Evaluation for Each Salt Model on the Full Dataset"
      ],
      "metadata": {
        "id": "Isfb3ijU3ocy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salt_mse = {}\n",
        "salt_r2 = {}\n",
        "model_paths = {}\n",
        "repo_path = \"CHEMENG177\"\n",
        "model_dir = os.path.join(repo_path, \"saved_models\")\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "scalers = {}\n",
        "for salt in X.keys():\n",
        "    print(f\"\\nTraining on best hyperparameters for {salt}...\\n\")\n",
        "\n",
        "    X_train = X_fulltrain[salt]\n",
        "    y_train = y_fulltrain[salt]\n",
        "    X_eval = X_test[salt]\n",
        "    y_eval = y_test[salt]\n",
        "\n",
        "    (epochs, batch_size) = best_hyperparams[salt]\n",
        "\n",
        "    # Scale the data\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_eval = scaler.transform(X_eval)\n",
        "\n",
        "    model = best_models[salt]\n",
        "    model.train(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "    # Evaluate Model\n",
        "    mse, r2 = model.evaluate(X_eval, y_eval)\n",
        "\n",
        "    salt_mse[salt] = mse\n",
        "    salt_r2[salt] = r2\n",
        "    scalers[salt] = scaler\n",
        "\n",
        "    print(f\"\\nFinal results for {salt} with {epochs} epochs and {batch_size} batch size:\")\n",
        "    print(f\"  MSE: {mse:.4f}\")\n",
        "    print(f\"  R2: {r2:.4f}\")\n",
        "    model_path = os.path.join(model_dir, f\"{salt}_nn_model.h5\")  # Model save path\n",
        "    model.model.save(model_path)\n",
        "\n",
        "    # Store model path\n",
        "    model_paths[salt] = model_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lhEFGbcflig",
        "outputId": "0d49a9f9-3693-424c-eda4-1c2e6d0f024d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training on best hyperparameters for LiPF6...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final results for LiPF6 with 100 epochs and 64 batch size:\n",
            "  MSE: 0.1957\n",
            "  R2: 0.9890\n",
            "\n",
            "Training on best hyperparameters for LiBF4...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final results for LiBF4 with 100 epochs and 32 batch size:\n",
            "  MSE: 0.2856\n",
            "  R2: 0.8931\n",
            "\n",
            "Training on best hyperparameters for LiAsF6...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final results for LiAsF6 with 100 epochs and 32 batch size:\n",
            "  MSE: 0.1970\n",
            "  R2: 0.9903\n",
            "\n",
            "Training on best hyperparameters for LiBOB...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final results for LiBOB with 100 epochs and 64 batch size:\n",
            "  MSE: 0.7348\n",
            "  R2: 0.9584\n"
          ]
        }
      ]
    }
  ]
}